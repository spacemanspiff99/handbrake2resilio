---
description:
globs:
alwaysApply: true
---

##################################
File and Folder organization rules (BEFORE creating a new files or folders)

1. **No files in root directory** - everything must be in respective folders
2. **No duplicate folders** - check existing structure before creating new folders
3. **Follow pattern:** `rep-engine-service/[service-name]/[function-name]/`. also but things like tests in a subfolder to the function (i.e. [function-name]/unit-tests). Do not create more than 5 unrelated files - i.e. if there are more than 5 deployment scripts, create a folder called 'deployment' and move them all there.
4. **Before creating folders:**
   - Search existing workspace for similar folders
   - Use existing locations - DO NOT create duplicates
   - Report any duplicate folders found and recommend consolidation
   - There is one central migraitons folder for the project, do not create other database migration folders
5. **If duplicates exist:** Immediately report and suggest cleanup plan
6. **Respect repository structure:** Keep code organized within the repository
7. **File naming:** Create versions of files (v1, v2, etc... instead of slightly changing files like deploy, deploy_new, deploy_simple, make it deploy001, deploy002, deploy003)

# Senior DevOps Engineering Rules for Project Deployment

# Ensures clean, reproducible deployments and prevents stale container issues

## üö® CRITICAL DEPLOYMENT RULES - ALWAYS FOLLOW

### Rule 1: MANDATORY CLEAN DEPLOYMENT PROCESS FOR DEV

When deploying ANY code changes to 192.168.10.18 (dev server):

**STEP 1: STOP AND REMOVE PROJECT-SPECIFIC CONTAINERS**

```bash
# Define project name (replace with your current project)
PROJECT_NAME="your-project-name"

# Stop and remove containers matching the project name
ssh akun@192.168.10.18 "docker ps -a --filter \"name=\$PROJECT_NAME\" --format '{{.ID}}' | xargs -r docker stop 2>/dev/null || true"
ssh akun@192.168.10.18 "docker ps -a --filter \"name=\$PROJECT_NAME\" --format '{{.ID}}' | xargs -r docker rm 2>/dev/null || true"

# Also check for containers using project-specific ports (update ports as needed)
PROJECT_PORTS="8080 3000 8081"
for port in $PROJECT_PORTS; do
    ssh akun@192.168.10.18 "docker ps --filter \"publish=\$port\" --format '{{.ID}}' | xargs -r docker stop 2>/dev/null || true"
    ssh akun@192.168.10.18 "docker ps -a --filter \"publish=\$port\" --format '{{.ID}}' | xargs -r docker rm 2>/dev/null || true"
done
```

**STEP 2: REMOVE PROJECT-SPECIFIC DOCKER IMAGES**

```bash
# Remove images matching the project name
ssh akun@192.168.10.18 "docker images --filter \"reference=\$PROJECT_NAME*\" --format '{{.ID}}' | xargs -r docker rmi --force 2>/dev/null || true"
ssh akun@192.168.10.18 "docker images --filter \"reference=*\$PROJECT_NAME*\" --format '{{.ID}}' | xargs -r docker rmi --force 2>/dev/null || true"

# Remove dangling images (untagged images that are no longer referenced)
ssh akun@192.168.10.18 "docker images --filter 'dangling=true' --format '{{.ID}}' | xargs -r docker rmi 2>/dev/null || true"
```

**STEP 3: CLEAN PROJECT-SPECIFIC BUILD CACHE AND VOLUMES**

```bash
# Clean only dangling build cache and volumes (safer than removing everything)
ssh akun@192.168.10.18 "docker system prune -f"
ssh akun@192.168.10.18 "docker builder prune -f"

# Remove project-specific volumes if they exist
ssh akun@192.168.10.18 "docker volume ls --filter \"name=\$PROJECT_NAME\" --format '{{.Name}}' | xargs -r docker volume rm 2>/dev/null || true"
```

**STEP 4: REMOVE PROJECT BUILD FILES FROM HOME DIRECTORY**

```bash
# Remove project-specific build files (update pattern to match your project)
ssh akun@192.168.10.18 "cd /home/akun && rm -rf \$PROJECT_NAME* *.tar.gz *.zip docker-compose* Dockerfile* requirements* deploy* test* verify* standalone*"
```

**STEP 5: KILL ANY LINGERING PROCESSES ON TARGET PORTS**

```bash
# Kill processes on project-specific ports
for port in $PROJECT_PORTS; do
    ssh akun@192.168.10.18 "fuser -k \$port/tcp 2>/dev/null || true"
done

# Kill project-specific processes (update patterns as needed)
ssh akun@192.168.10.18 "pkill -f \"python.*\$PROJECT_NAME\" 2>/dev/null || true"
ssh akun@192.168.10.18 "pkill -f \"\$PROJECT_NAME\" 2>/dev/null || true"
```

**STEP 6: ONLY THEN PROCEED WITH DEPLOYMENT**

- Upload new code
- Build fresh images
- Deploy containers

### Rule 2: CONTAINER NAMING CONVENTIONS

Always use consistent, predictable container names with project prefix:

- `{project-name}-api-gateway` for API Gateway
- `{project-name}-frontend` for Frontend Service
- `{project-name}-backend` for Backend Service
- `{project-name}-{service-name}` for other services

Example: For project "handbrake2resilio":

- `handbrake2resilio-api-gateway`
- `handbrake2resilio-frontend`
- `handbrake2resilio-handbrake`

### Rule 3: DEPLOYMENT VERIFICATION

After every deployment, ALWAYS verify:

```bash
ssh akun@192.168.10.18 "docker ps --format 'table {{.Names}}\t{{.Status}}\t{{.Ports}}'"
ssh akun@192.168.10.18 "curl -s -o /dev/null -w '%{http_code}' http://localhost:8080/health"
ssh akun@192.168.10.18 "curl -s -o /dev/null -w '%{http_code}' http://localhost:3000"
```

### Rule 4: NO INCREMENTAL UPDATES

‚ùå NEVER attempt to update running containers
‚ùå NEVER rely on Docker cache for production deployments
‚ùå NEVER assume containers will pick up new code automatically
‚úÖ ALWAYS do full clean rebuilds for production

### Rule 5: SOURCE CODE MANAGEMENT ON SERVER

Keep server clean - remove project-specific build artifacts:

- `{project-name}/` directories
- `*.tar.gz` files
- `docker-compose*.yml` files
- `Dockerfile*` files
- `requirements*.txt` files
- Any `deploy_*`, `test_*`, `verify_*` scripts

### Rule 6: DEPLOYMENT SCRIPT TEMPLATE

When creating deployment scripts, use this template:

```bash
#!/bin/bash
set -e  # Exit on any error

# Configure your project settings here
PROJECT_NAME="your-project-name"
PROJECT_PORTS="8080 3000 8081"  # Update with your project ports
SERVER_IP="192.168.10.18"
SERVER_USER="akun"

echo "üßπ STEP 1: Stopping project containers..."
ssh ${SERVER_USER}@${SERVER_IP} "docker ps -a --filter \"name=${PROJECT_NAME}\" --format '{{.ID}}' | xargs -r docker stop 2>/dev/null || true"

echo "üóëÔ∏è STEP 2: Removing project containers..."
ssh ${SERVER_USER}@${SERVER_IP} "docker ps -a --filter \"name=${PROJECT_NAME}\" --format '{{.ID}}' | xargs -r docker rm 2>/dev/null || true"

echo "üî• STEP 3: Removing project images..."
ssh ${SERVER_USER}@${SERVER_IP} "docker images --filter \"reference=${PROJECT_NAME}*\" --format '{{.ID}}' | xargs -r docker rmi --force 2>/dev/null || true"
ssh ${SERVER_USER}@${SERVER_IP} "docker images --filter \"reference=*${PROJECT_NAME}*\" --format '{{.ID}}' | xargs -r docker rmi --force 2>/dev/null || true"

echo "üßΩ STEP 4: Cleaning Docker system..."
ssh ${SERVER_USER}@${SERVER_IP} "docker system prune -f"
ssh ${SERVER_USER}@${SERVER_IP} "docker builder prune -f"

echo "üìÅ STEP 5: Cleaning project files..."
ssh ${SERVER_USER}@${SERVER_IP} "cd /home/${SERVER_USER} && rm -rf ${PROJECT_NAME}* *.tar.gz *.zip docker-compose* Dockerfile* requirements* deploy* test* verify* standalone*"

echo "‚öîÔ∏è STEP 6: Killing lingering processes..."
for port in $PROJECT_PORTS; do
    ssh ${SERVER_USER}@${SERVER_IP} "fuser -k ${port}/tcp 2>/dev/null || true"
done

echo "üì¶ STEP 7: Uploading new code..."
tar -czf ${PROJECT_NAME}-$(date +%Y%m%d-%H%M%S).tar.gz ${PROJECT_NAME}/
scp ${PROJECT_NAME}-*.tar.gz ${SERVER_USER}@${SERVER_IP}:~/
ssh ${SERVER_USER}@${SERVER_IP} "cd ~ && tar -xzf ${PROJECT_NAME}-*.tar.gz"

echo "üèóÔ∏è STEP 8: Building fresh images..."
# IMPORTANT: Verify all required files exist before building
ssh ${SERVER_USER}@${SERVER_IP} "cd ~/${PROJECT_NAME} && find . -name 'Dockerfile*' -o -name 'requirements*.txt' -o -name 'package.json' | sort"

echo "üöÄ STEP 9: Starting services..."
# Use specific deployment script from project
ssh ${SERVER_USER}@${SERVER_IP} "cd ~/${PROJECT_NAME}/deployment && ./deploy_simple.sh"

echo "‚úÖ STEP 10: Verifying deployment..."
# Wait for services to start
sleep 10
ssh ${SERVER_USER}@${SERVER_IP} "docker ps --format 'table {{.Names}}\t{{.Status}}\t{{.Ports}}'"
curl -s -o /dev/null -w '%{http_code}' http://${SERVER_IP}:8080/health || echo "‚ùå API health check failed"
curl -s -o /dev/null -w '%{http_code}' http://${SERVER_IP}:3000 || echo "‚ùå Frontend check failed"

echo "üß™ Testing core functionality..."
# Add basic functionality tests here
curl -X POST http://${SERVER_IP}:8080/api/tabs -H "Content-Type: application/json" \
  -d '{"name": "Deployment Test", "destination": "/test/deploy", "source_type": "tv"}' \
  && echo "‚úÖ Tab creation test passed" || echo "‚ùå Tab creation test failed"

echo "üßπ Cleanup deployment artifacts..."
rm -f ${PROJECT_NAME}-*.tar.gz
```

### Rule 7: ENVIRONMENT-SPECIFIC CONFIGURATIONS

- Development: Can use incremental updates and Docker cache
- Production (192.168.10.18): MUST use clean deployment process
- Always specify exact versions in package.json and requirements.txt

### Rule 8: ROLLBACK STRATEGY

Before deploying:

- Tag current working Docker images with timestamp
- Keep previous working build artifacts as backup
- Have rollback commands ready

### Rule 9: LOGGING AND MONITORING

After every deployment:

- Check container logs: `docker logs <container-name>`
- Monitor resource usage: `docker stats`
- Verify all health endpoints are responding

### Rule 10: DEPENDENCY AND CONFIGURATION MANAGEMENT

**CRITICAL: Always verify required files exist before deployment**

Before building containers, ensure these files exist:

- `Dockerfile` (with correct COPY statements)
- `requirements.txt` or `package.json` (with exact versions)
- `config.py` or configuration files (if imported by application)
- Environment variable files or build-time environment setup

**Environment Variable Best Practices:**

- Frontend (React): Use build-time ENV variables in Dockerfile, not runtime
- Backend: Use runtime environment variables with defaults
- Always test with target server IP addresses, not localhost
- Document all required environment variables

**Example Frontend Dockerfile Pattern:**

```dockerfile
# Stage 1: Build with environment variables
FROM node:18-alpine as build-stage
WORKDIR /app
COPY package*.json ./
RUN npm install
COPY . .

# Set build-time environment variables
ENV REACT_APP_API_URL=http://192.168.10.18:8080
ENV REACT_APP_WS_URL=ws://192.168.10.18:8080
ENV REACT_APP_SOCKET_PATH=/socket.io/

RUN npm run build

# Stage 2: Serve
FROM nginx:alpine
COPY --from=build-stage /app/build /usr/share/nginx/html
EXPOSE 80
```

### Rule 11: SECURITY CONSIDERATIONS

- Always use `--no-new-privileges` in Docker configs
- Run containers as non-root when possible
- Clean up sensitive files (env files, keys) after deployment
- Use secrets management for production credentials

## üéØ SUMMARY: The Golden Rule

**"When in doubt, nuke it and rebuild from scratch"**

This approach takes slightly longer but ensures:
‚úÖ No stale containers
‚úÖ No cached build issues  
‚úÖ No port conflicts
‚úÖ No version mismatches
‚úÖ Reproducible deployments
‚úÖ Easier debugging

Remember: In production, reliability > speed. A 5-minute clean rebuild is better than hours debugging deployment issues.

## üîß PROJECT-SPECIFIC DEPLOYMENT GUIDELINES

### Frontend Deployment (React/Vue/Angular)

When updating frontend applications:

1. Always rebuild the entire Docker image with `--no-cache`
2. Verify Node.js dependencies are up to date
3. Check for package compatibility issues
4. Test the build locally before deploying to server
5. Verify static assets are properly served

### Backend Deployment (Python/Node.js/etc.)

When updating backend services:

1. Stop the old container completely before starting new one
2. Verify dependencies in requirements.txt/package.json
3. Check database migrations if any
4. Ensure API endpoints and connections are properly configured
5. Verify environment variables are correctly set

### Container Orchestration

When using docker-compose:

1. Always use `docker-compose down` before `docker-compose up`
2. Use `--build --force-recreate` flags for clean rebuilds
3. Verify all services start in correct order with dependency checks
4. Monitor logs during startup for any errors

### File Transfer Best Practices

When uploading code to server:

1. Create timestamped tarballs: `{project-name}-$(date +%Y%m%d-%H%M%S).tar.gz`
2. Upload to `/tmp` first, then move to target location
3. Verify file integrity after transfer
4. Clean up old tarballs to save disk space

## üö® TROUBLESHOOTING COMMON DEPLOYMENT ISSUES

### Issue 1: Container Exits Immediately After Start

**Symptoms:** Container shows in `docker ps -a` as "Exited (1)" status

**Debug Steps:**

```bash
# Check container logs
ssh akun@192.168.10.18 "docker logs <container-name>"

# Common causes:
# - Missing import files (config.py, auth.py, etc.)
# - Python module import errors
# - Missing dependencies in requirements.txt
# - Incorrect file paths in Dockerfile COPY statements
```

**Solutions:**

- Verify all imported files exist in the Docker build context
- Create missing configuration files with proper defaults
- Use standalone versions without external dependencies
- Add `allow_unsafe_werkzeug=True` for SocketIO in development

### Issue 2: Frontend Shows Wrong API URL

**Symptoms:** Frontend makes requests to localhost instead of server IP

**Debug Steps:**

```bash
# Check built frontend JavaScript for API URLs
ssh akun@192.168.10.18 "docker exec <frontend-container> find /usr/share/nginx/html -name '*.js' -exec grep -l 'localhost\\|127.0.0.1' {} \\;"
```

**Solutions:**

- Set environment variables at Docker build time, not runtime
- Rebuild frontend container with `--no-cache` flag
- Verify environment variables are in Dockerfile, not docker run command

### Issue 3: Stale Containers Still Running

**Symptoms:** Old containers respond instead of new deployment

**Debug Steps:**

```bash
# Check all containers with timestamps
ssh akun@192.168.10.18 "docker ps -a --format 'table {{.Names}}\\t{{.Status}}\\t{{.CreatedAt}}'"

# Check which container is actually responding
ssh akun@192.168.10.18 "docker ps --filter 'publish=8080' --format '{{.Names}}'"
```

**Solutions:**

- Always follow the complete cleanup process in Rule 1
- Use specific container names, not generic ones
- Verify port bindings match expected containers

### Issue 4: Docker Build Cache Issues

**Symptoms:** Changes not reflected in built containers despite rebuild

**Debug Steps:**

```bash
# Force complete rebuild
ssh akun@192.168.10.18 "docker build --no-cache -t <image-name> ."

# Check build context
ssh akun@192.168.10.18 "docker build --progress=plain --no-cache -t <image-name> ."
```

**Solutions:**

- Always use `--no-cache` for production builds
- Clean Docker build cache between deployments
- Verify file timestamps in build context
